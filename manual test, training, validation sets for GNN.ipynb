{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9427408",
   "metadata": {},
   "source": [
    "# libraries, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4e97f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import pandas as pd \n",
    "from torch_geometric.transforms import RemoveTrainingClasses, RandomNodeSplit  \n",
    "import torch.nn.functional as F\n",
    "import torch.nn\n",
    "from torch_geometric.nn import SAGEConv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#datasets\n",
    "from torch_geometric.datasets import AttributedGraphDataset\n",
    "from torch_geometric.datasets import Planetoid \n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "\n",
    "# evaluation \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7cb7c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download datasets\n",
    "datasets = ['cora_A', 'citeseer_A', 'pubmed_A', 'cora_P', 'citeseer_P', 'pubmed_P']\n",
    "\n",
    "# AGD\n",
    "cora_A = AttributedGraphDataset(root='AGD', name='Cora')\n",
    "citeseer_A = AttributedGraphDataset(root='AGD', name='CiteSeer')\n",
    "pubmed_A =  AttributedGraphDataset(root='AGD', name='PubMed')\n",
    "\n",
    "# planetoid\n",
    "cora_P = Planetoid(root='Planetoid', name='Cora', transform=NormalizeFeatures())\n",
    "citeseer_P = Planetoid(root='Planetoid', name='CiteSeer',transform=NormalizeFeatures())\n",
    "pubmed_P =  Planetoid(root='Planetoid', name='PubMed',transform=NormalizeFeatures())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e5a232",
   "metadata": {},
   "source": [
    "# network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3642a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#neural network model \n",
    "#implement a two-layer GraphSage from GCN example:\n",
    "\n",
    "class GraphSage(torch.nn.Module):\n",
    "    def __init__(self, attributes, classes, dimension=32):\n",
    "        super(GraphSage, self).__init__() \n",
    "        self.conv1 = SAGEConv(attributes, dimension) \n",
    "        self.conv2 = SAGEConv(dimension, classes)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index \n",
    "\n",
    "        x = self.conv1(x, edge_index) #layer 1 \n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training) \n",
    "        x = self.conv2(x, edge_index) #layer 2 \n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c97541e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## training & evaluating \n",
    "class accuracy():\n",
    "    def __init__(self, model, device, dataset, data):\n",
    "        self.model = model(attributes=dataset.num_node_features, classes=dataset.num_classes, dimension=32).to(device)\n",
    "        self.data = data\n",
    "    \n",
    "    def train(self, num_epochs, lr=0.001):\n",
    "        loss_vals= []\n",
    "        valid_vals= []\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr, weight_decay=5e-4)\n",
    "        print('Training the model\\n')\n",
    "\n",
    "        for epoch in range(num_epochs): \n",
    "            optimizer.zero_grad() \n",
    "            out = self.model(self.data)\n",
    "            loss = F.cross_entropy(input=out[self.data.train_mask], target=self.data.y[self.data.train_mask]) \n",
    "            loss.backward() \n",
    "            optimizer.step()  \n",
    " \n",
    "    def evaluate(self, dimension=1, write_confusion=False):\n",
    "        # returns a confusion matrix if set write_confusion=True\n",
    "        print('Evaluating the model\\n')\n",
    "        self.model.eval()\n",
    "        pred = self.model(self.data).argmax(dimension)        \n",
    "        correct = (pred[self.data.test_mask] == self.data.y[self.data.test_mask]).sum()\n",
    "        acc = int(correct) / int(self.data.test_mask.sum())\n",
    "        print(f'Accuracy: {acc:.4f}')\n",
    "\n",
    "        if write_confusion: \n",
    "            new = confusion_matrix(self.data.y[self.data.test_mask].numpy(), pred[self.data.test_mask].numpy(), normalize='true')\n",
    "            return(pd.DataFrame(data=new))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10495a7",
   "metadata": {},
   "source": [
    "# Default split vs Random split\n",
    "- leave one out manually, default splits and random splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97d2910",
   "metadata": {},
   "source": [
    "## functions - take out a node/multiple nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3490272",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a manual train mask function \n",
    "#train_mask = a list of booleans to mask, same length as num_nodes\n",
    "from typing import Optional, Tuple, Union\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch_geometric.data import Data, HeteroData\n",
    "from torch_geometric.transforms import BaseTransform\n",
    "\n",
    "\n",
    "def random_train_mask(dataset):\n",
    "#     cora_A_data = transform_nodes(cora_A[0])'\n",
    "    transform_nodes = RandomNodeSplit(split = 'test_rest') # RandomNodeSplit is a class \n",
    "    data = transform_nodes(dataset[0])\n",
    "    return data\n",
    "\n",
    "def split(which_nodes, num_nodes, num_test_nodes) -> Tuple[Tensor, Tensor, Tensor]:\n",
    "    train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    val_mask = torch.ones(num_nodes, dtype=torch.bool)\n",
    "    test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "\n",
    "    count = 0\n",
    "    for i in range(num_nodes):  #separate the testing set\n",
    "        if count == num_test_nodes: break \n",
    "        if i not in which_nodes: \n",
    "            test_mask[i] = True\n",
    "            count+=1\n",
    "\n",
    "    for i in which_nodes: #separate the training and validation set\n",
    "        train_mask[i] = True  \n",
    "        val_mask[i] = False\n",
    "\n",
    "    return train_mask, val_mask, test_mask\n",
    "\n",
    "def create_train_mask(dataset, which_nodes, test_ratio, default_train=False):\n",
    "    \"\"\"\n",
    "    which_nodes: a list of integers(node indices) that will be masked\n",
    "    test_ratio: float, what percentage of the entire nodes that will be used for the testing set\n",
    "    \n",
    "    returns: data with train_mask, val_mask, test_mask attributes manually set\n",
    "    \"\"\"\n",
    "    \n",
    "    data = dataset[0]\n",
    "    num_nodes = data.num_nodes\n",
    "    num_test_nodes = test_ratio * data.num_nodes\n",
    "        \n",
    "    if default_train: \n",
    "        # random split using the pyg function \n",
    "        return random_train_mask(dataset) \n",
    "    \n",
    "    else: \n",
    "        # manual split taking out the designated nodes\n",
    "        for store in data.node_stores:\n",
    "            train_masks, val_masks, test_masks = zip(*[split(which_nodes, num_nodes, num_test_nodes)])\n",
    "            store.train_mask = torch.stack(train_masks, dim=-1).squeeze(-1)\n",
    "            store.val_mask = torch.stack(val_masks, dim=-1).squeeze(-1)\n",
    "            store.test_mask = torch.stack(test_masks, dim=-1).squeeze(-1)\n",
    "        return data\n",
    "\n",
    "def from_numpy(train, val, test):\n",
    "    return torch.from_numpy(train), torch.from_numpy(val), torch.from_numpy(test)\n",
    "\n",
    "def mask_a_node(data, which_node):\n",
    "    \"\"\"\n",
    "    given a dataset, mask a node of given index into False (i.e. mask one datapoint in the training set)\n",
    "    note: the dataset must already have a preexisting train_mask tensor\n",
    "    \n",
    "    which_node: an integer index of a node to be masked \n",
    "    \"\"\"\n",
    "    train_mask = data.train_mask.numpy()\n",
    "    val_mask = data.val_mask.numpy()\n",
    "    test_mask = data.test_mask.numpy()\n",
    "    \n",
    "    for store in data.node_stores:\n",
    "        train_mask[which_node] = 'True'\n",
    "        val_mask[which_node] = 'False'\n",
    "        test_mask[which_node] = 'False'\n",
    "        \n",
    "\n",
    "        train_masks, val_masks, test_masks = zip(*[from_numpy(train_mask, val_mask, test_mask)])\n",
    "        \n",
    "        store.train_mask = torch.stack(train_masks, dim=-1).squeeze(-1)\n",
    "        store.val_mask = torch.stack(val_masks, dim=-1).squeeze(-1)\n",
    "        store.test_mask = torch.stack(test_masks, dim=-1).squeeze(-1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a2ba36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False, False, False,  True,  True,  True, False, False, False, False])\n",
      "tensor([ True,  True, False,  True,  True,  True, False, False, False, False])\n"
     ]
    }
   ],
   "source": [
    "## define transform_nodes\n",
    "cora_A_data_manual = create_train_mask(cora_A, [3, 4, 5], 0.2, default_train=False)\n",
    "print(cora_A_data_manual.train_mask[:10])\n",
    "cora_A_data_one = mask_a_node(cora_A_data_manual, [0, 1])\n",
    "print(cora_A_data_manual.train_mask[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679f5de8",
   "metadata": {},
   "source": [
    "### function - take out a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbb78b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a manual train class function \n",
    "def random_train_class(dataset, which_class):\n",
    "    \"\"\"\n",
    "    note: dataset must have a preexisting train_mask\n",
    "    classes (List[int]) â€“ The classes to remove from the training set.\n",
    "    \"\"\"\n",
    "#     cora_A_data = transform_nodes(cora_A[0])'\n",
    "    transform_class = RemoveTrainingClasses(which_class) # RandomNodeSplit is a class \n",
    "    data = transform_class(dataset[0])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cec10b",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa1bf733",
   "metadata": {},
   "outputs": [],
   "source": [
    "cora_A_random_data = random_train_mask(cora_A)\n",
    "citeseer_A_random_data = random_train_mask(citeseer_A)\n",
    "pubmed_A_random_data = random_train_mask(pubmed_A) # caution, don't reiterate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160fec06",
   "metadata": {},
   "source": [
    "## cora_A\n",
    "- cora_A_random_data\n",
    "- cora_A_data_manual\n",
    "- cora_A_data_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "907efde8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#cora_A \n",
    "deviceA = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "deviceB = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "deviceC = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dataA = cora_A_random_data.to(deviceA)\n",
    "dataB = cora_A_data_manual.to(deviceB)\n",
    "dataC = cora_A_data_one.to(deviceC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ede798b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model\n",
      "\n",
      "Evaluating the model\n",
      "\n",
      "Accuracy: 0.6349\n"
     ]
    }
   ],
   "source": [
    "cora_AA = accuracy(GraphSage,deviceA, cora_A, dataA)\n",
    "cora_AA.train(50) \n",
    "evalA = cora_AA.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c5b1fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model\n",
      "\n",
      "Evaluating the model\n",
      "\n",
      "Accuracy: 0.2144\n"
     ]
    }
   ],
   "source": [
    "cora_AB = accuracy(GraphSage, deviceB, cora_A, dataB)\n",
    "cora_AB.train(50) \n",
    "evalB = cora_AB.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b639bc07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model\n",
      "\n",
      "Evaluating the model\n",
      "\n",
      "Accuracy: 0.2181\n"
     ]
    }
   ],
   "source": [
    "cora_AC = accuracy(GraphSage, deviceC, cora_A, dataC)\n",
    "cora_AC.train(50) \n",
    "evalB = cora_AC.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1097ff15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idea: build a class that returns a custom train_mask tensor? \n",
    "# train_mask usage: data[train_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "362542b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'x': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'edge_index': tensor([[   0,    0,    0,  ..., 2707, 2707, 2707],\n",
      "        [ 633, 1862, 2582,  ...,  598, 1473, 2706]]), 'y': tensor([3, 4, 4,  ..., 3, 3, 3]), 'train_mask': tensor([ True,  True,  True,  ..., False, False, False]), 'val_mask': tensor([False, False, False,  ..., False, False, False]), 'test_mask': tensor([False, False, False,  ...,  True,  True,  True])}]\n"
     ]
    }
   ],
   "source": [
    "cora_P_class = random_train_class(cora_P, [0])\n",
    "print(cora_P_class.node_stores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
