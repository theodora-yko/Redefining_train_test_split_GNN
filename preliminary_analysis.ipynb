{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5a7a8610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file specific libraries\n",
    "import torch\n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "54328e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from GNN import *\n",
    "from train_mask import *\n",
    "from data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf831f46",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f73dca88",
   "metadata": {},
   "outputs": [],
   "source": [
    "cora_A_random_data = random_train_mask(cora_A)\n",
    "cora_P_data_manual = create_train_mask(cora_P, [1,2,3,4,5,6,7], 0.3)\n",
    "cora_P_data_one = mask_a_node(cora_P, [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c6e903e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model\n",
      "Evaluating the model\n",
      "Accuracy: 0.1655\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "cora_P2 = accuracy(GraphSAGE, device, cora_P, cora_P_data_manual)\n",
    "cora_P2.train(50) \n",
    "evalP = cora_P2.evaluate()\n",
    "\n",
    "## note: \"accuracy object is not subscriptable\" error is because I probably named one of the variable name \n",
    "## using the dataset name rip so just rename the devices, data, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "555ee5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_accuracy(model, dataset, data, epoch_size, indicate): \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    new_class = GNN.accuracy(model, device, dataset, data, indicate=indicate)              \n",
    "    new_class.train(epoch_size)\n",
    "    accuracy = new_class.evaluate()\n",
    "    return accuracy\n",
    "    \n",
    "#     if compute_gradient: \n",
    "#         output, accuracy = new_class.evaluate(return_prediction=compute_gradient)\n",
    "#         accuracy = round(accuracy,3)\n",
    "#         out\n",
    "    \n",
    "#     return accuracy, gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c1b251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_accuracy(model, dataset, data, epoch_size, original_output=None, indicate, compute_gradient=False):\n",
    "    \"\"\"\n",
    "    original_output = output using the original data, optional\n",
    "    indicate = Boolean\n",
    "    compute_gradient = Boolean\n",
    "    \n",
    "    returns: accuracy of the model trained using the given data \n",
    "    \"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    new_class = GNN.accuracy(model, device, dataset, data, indicate=indicate)              \n",
    "    new_class.train(epoch_size)\n",
    "\n",
    "    if compute_gradient: \n",
    "        output, accuracy = new_class.evaluate(return_prediction=compute_gradient)\n",
    "        original_ouput\n",
    "        accuracy = round(accuracy,3)\n",
    "        return accuracy, gradients\n",
    "    \n",
    "    else: return new_class.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e4f80348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, math\n",
    "from copy import deepcopy\n",
    "\n",
    "class find_the_influential_class(): \n",
    "    \"\"\"\n",
    "    given a dataset, mask each node at a time and compare accuracy to find the most influential point \n",
    "\n",
    "    note: the dataset must already have a preexisting train_mask tensor\n",
    "    note: will only mask the points in the current train_mask \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, dataset, epoch_size):\n",
    "        self.model = model\n",
    "        self.dataset = dataset\n",
    "        self.epoch_size = epoch_size\n",
    "        self.init_accuracy = return_accuracy(model, dataset, dataset[0], epoch_size, False)\n",
    "        self.accuracy = deepcopy(self.init_accuracy)\n",
    "        self.influential = {}\n",
    "    \n",
    "    def influential_accuracy(self, indicate=False, record_time=True, index_range=True, compute_gradient=False):\n",
    "        ##question: integer = integer; would this be equal or a copy?\n",
    "        \n",
    "        start_time = time.time()\n",
    "        data = self.dataset[0]\n",
    "\n",
    "        ## calculate the initial accuracy using the original data in the the dataset \n",
    "        print(f\"\\ninitial accuracy given the initial data: {self.init_accuracy}\")\n",
    "\n",
    "        # calculate new accuracy and update \"influential\" if it improves the accuracy \n",
    "        train_mask = data.train_mask.numpy()\n",
    "        leng = len(data.x)\n",
    "\n",
    "        for i in range(leng): \n",
    "            if train_mask[i]:\n",
    "                if indicate: print(f\"--Masking: Excluding point number {i}--\")\n",
    "                data = mask_a_node(self.dataset, i)\n",
    "                new_accuracy = return_accuracy(self.model, self.dataset, data, self.epoch_size, indicate)\n",
    "                if new_accuracy >= self.accuracy: \n",
    "                    self.accuracy = new_accuracy\n",
    "                    self.influential[i] = new_accuracy\n",
    "                \n",
    "        if record_time: print(\"--- %s seconds ---\" % round((time.time() - start_time), 1))\n",
    "        if index_range: print(f\"lowest accuracy: {self.init_accuracy}, highest accuracy: {self.accuracy}, range: {self.accuracy-self.init_accuracy}\")\n",
    "        return self.influential     \n",
    "\n",
    "    #post processing  \n",
    "    def top25(self): ## print the upper 75th percentile\n",
    "        leng = len(self.influential)\n",
    "        print(leng)\n",
    "        top25 = math.floor(leng* 0.75) #rounding down in case there are only one or two influential points\n",
    "        influence_index = list(self.influential.keys())[top75:]\n",
    "        print(f\"{leng} influential points, 75th percentiles: \")\n",
    "        for i in influence_index: \n",
    "            print(f\"node {i}, accuracy: {self.influential[i]}\")\n",
    "\n",
    "    def to_percentage(self): ## use softmax to update influencial.values() to softmax percentage\n",
    "        for key, value in self.influential.items(): \n",
    "            self.influential[key] = round((value-self.init_accuracy)/value,2)*100\n",
    "            print(f\"masking node {key} increases the prediction accuracy by {self.influential[key]}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0e4e599f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "initial accuracy given the initial data: 0.08956692913385826\n",
      "--- 48.5 seconds ---\n",
      "lowest accuracy: 0.08956692913385826, highest accuracy: 0.3229873908826382, range: 0.23342046174877995\n",
      "masking node 0 increases the prediction accuracy by 0.0%\n",
      "masking node 2 increases the prediction accuracy by 32.0%\n",
      "masking node 5 increases the prediction accuracy by 72.0%\n",
      "masking node 15 increases the prediction accuracy by 72.0%\n",
      "masking node 19 increases the prediction accuracy by 72.0%\n",
      "masking node 28 increases the prediction accuracy by 72.0%\n",
      "masking node 30 increases the prediction accuracy by 72.0%\n"
     ]
    }
   ],
   "source": [
    "new = find_the_influential_class(GraphSAGE, cora_P, 1)\n",
    "new.influential_accuracy()\n",
    "new.to_percentage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dce760b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.0, 2: 32.0, 5: 72.0, 15: 72.0, 19: 72.0, 28: 72.0, 30: 72.0}\n"
     ]
    }
   ],
   "source": [
    "print(new.influential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e455855d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_testing(test_size, model, dataset, epoch_size):\n",
    "    record = {}\n",
    "    \n",
    "    for i in range(test_size): \n",
    "        influential = find_the_influential(model, dataset, epoch_size)\n",
    "        for key, value in influential.items():\n",
    "            if key in record.keys(): \n",
    "                record[key] += value\n",
    "            else: \n",
    "                record[key] = value\n",
    "    \n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff1d753",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_testing(5, GraphSAGE, cora_P, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e512e92b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97a2169c",
   "metadata": {},
   "source": [
    "# new todo\n",
    "1. plot the distribution \n",
    "    1. plot a ziploc and rank the nodes by the number of time they appear \n",
    "    2. cumulative distribution histogram\n",
    "    3. magnitude - average magnitude per points \n",
    "    4. print the degree of each nodes, betweenness and centrality (copy networkX library) \n",
    "https://networkx.org/documentation/networkx1.10/reference/generated/networkx.algorithms.centrality.betweenness_centrality.html\n",
    "https://networkx.org/documentation/networkx-1.10/reference/algorithms.centrality.html\n",
    "    5. degree vs influence\n",
    "    \n",
    "    **question: is the topological component of a node influential?**\n",
    "\n",
    "2. spatial relationships between the points \n",
    "    1. remove several points at a time - a point & neighbourhoods \n",
    "    2. top 25% - connected to each other? spatially distanced? \n",
    "    \n",
    "    \n",
    "3. see if the database is stable - notion of sensitivity \n",
    "4. approximate the influential points? cannot use iteration - we can maybe use gradients \n",
    "5. correlate an influence of a point to higher/lower impact on low degree node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2be454e",
   "metadata": {},
   "source": [
    "### difference calculation (2): average KL difference\n",
    "- y original - y_i\n",
    "- diff = ||Y_original - Y_i||^2\n",
    "- diff2 = mean(KL(Y^{(original)}_j - Y^{(-i)}_j)_ ) (average KL difference) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292a2d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e1515e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68d5218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bad0678",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73c24d3f",
   "metadata": {},
   "source": [
    "## 3. bootstrapping - node feature influence\n",
    "by swapping classes of one node \n",
    "instead of deleting points from the training set, switch its label and asses its participation that it leaves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "086a724a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a manual train class function \n",
    "def random_train_class(dataset, which_class):\n",
    "    \"\"\"\n",
    "    note: dataset must have a preexisting train_mask\n",
    "    classes (List[int]) â€“ The classes to remove from the training set.\n",
    "    \"\"\"\n",
    "#     cora_A_data = transform_nodes(cora_A[0])'\n",
    "    transform_class = RemoveTrainingClasses(which_class) # RandomNodeSplit is a class \n",
    "    data = transform_class(dataset[0])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753336d9",
   "metadata": {},
   "source": [
    "## 4. test the amount of separation we have between clusters \n",
    "suppose linear classifier, two sets of points and separating the two clusters (fit a line between two clusters) \n",
    "look at other types of loss ex. hinge lost \n",
    "hinge - maximise margin (Tries to look for good margin) \n",
    " (switching the cross entropy loss) \n",
    " https://pytorch.org/docs/stable/generated/torch.nn.HingeEmbeddingLoss.html\n",
    " https://pytorch.org/docs/stable/generated/torch.nn.MultiMarginLoss.html (use this instead of the above one!)\n",
    "  needs an additional line of code as one vs a bunch of clusters \n",
    "  \n",
    "  use a for loop, just assessing a small dataset so won't take too long\n",
    "\n",
    "want to be in the middle of two groups \n",
    "assess the separating margins between the two classes \n",
    "\n",
    "additional post-processing\n",
    "take the prediction score and compute clustering coefficients \n",
    "- https://scikit-learn.org/stable/modules/clustering.html#clustering-performance-evaluation\n",
    "\n",
    "**robustness of individual points, separating margins**\n",
    "**separation of clusters** - the intuition is not robust, take in y^hat and y^true data points\n",
    "\n",
    "**question on GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb96d9ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
